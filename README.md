# AI Builder Part 1: Thai NLP Dataset Generation and Utilities

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-brightgreen.svg)](https://www.python.org/)

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Dataset) ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Natural Language Processing (NLP) ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

## ‚ú® ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏Å (Key Features)

*   **Dataset Generation:**
    *   ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô NLP ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Large Language Models (LLM) ‡πÄ‡∏ä‡πà‡∏ô DeepSeek ‡∏ú‡πà‡∏≤‡∏ô API (`Script/Generate/generate_datasets_deepseek.py`)
    *   ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô: Text Classification, Question Answering (QA), Table QA, Zero-Shot Classification, Named Entity Recognition (NER), Translation (TH-EN), Summarization, Sentence Similarity, Text Generation, Style Transfer (Formal/Informal), Fill-Mask, Text Ranking.
*   **Dataset Utilities & Demonstrations (`Script/Dataset/`):**
    *   **Content Moderation:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (`content_moderation.py`)
    *   **Conversation Simulation:** ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (`conversation_simulation.py`)
    *   **FAQ Summarization:** ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (`faq_summarization.py`)
    *   **Named Entity Recognition (NER):** ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (`ner_handler.py`)
    *   **Paraphrase Identification:** ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô (`paraphrase_identification.py`)
    *   **Style Transfer:** ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£/‡πÑ‡∏°‡πà‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ (`style_transfer.py`)
    *   **Transcript Analysis:** ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤/‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏° (`transcript_handler.py`)
    *   **TTS Script Analysis:** ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Text-to-Speech (`tts_script_handler.py`)
*   **Model Management:**
    *   ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Pre-trained ‡∏à‡∏≤‡∏Å Hugging Face (`Script/download_model.py`)
    *   ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á Hugging Face Hub (`Script/upload_model_to_hf.py`)
*   **Pre-defined Datasets:**
    *   ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ (`Dataset/`, `DatasetCook/`, `DatasetNLP/`, `DatasetReasoning/`)

## üöÄ ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á (Installation)

1.  **Clone repository:**
    ```bash
    git clone <your-repository-url>
    cd aibuilderPart1
    ```
2.  **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Virtual Environment (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥):**
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # macOS/Linux
    source venv/bin/activate
    ```
3.  **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *(‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå `requirements.txt` ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÇ‡∏î‡∏¢ `pip freeze > requirements.txt` ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡πÄ‡∏ä‡πà‡∏ô `transformers`, `torch`, `pandas`, `requests`, `langchain`, `huggingface_hub`)*

4.  **‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment Variables (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dataset Generation):**
    *   ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `.env` ‡πÉ‡∏ô‡πÑ‡∏î‡πÄ‡∏£‡∏Å‡∏ó‡∏≠‡∏£‡∏µ‡∏£‡∏≤‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå
    *   ‡πÄ‡∏û‡∏¥‡πà‡∏° API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:
      ```dotenv
      DEEPSEEK_API_KEY="your_deepseek_api_key_here"
      ```
    *   ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå `generate_datasets_deepseek.py` ‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á `python-dotenv`: `pip install python-dotenv`)

## üõ†Ô∏è ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Usage)

‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà [**‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (./docs/USAGE.md)**](./docs/USAGE.md)

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô:**

1.  **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:**
    ```bash
    python Script/download_model.py
    ```
2.  **‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏£‡πâ‡∏≤‡∏á Dataset (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á):**
    ```bash
    python Script/Generate/generate_datasets_deepseek.py
    ```
    *(‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ `DEEPSEEK_API_KEY` ‡πÉ‡∏ô `.env` ‡πÅ‡∏•‡πâ‡∏ß)*

3.  **‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≤‡∏ò‡∏¥‡∏ï (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á - NER):**
    ```bash
    python Script/Dataset/ner_handler.py
    ```
    *(‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÉ‡∏ô `Script/Dataset/` ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏à‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏ò‡∏¥‡∏ï‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏°‡∏î‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á)*

## üìÅ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå (Project Structure)

```
aibuilderPart1/
‚îú‚îÄ‚îÄ Dataset/              # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ)
‚îú‚îÄ‚îÄ DatasetCook/          # ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠)
‚îú‚îÄ‚îÄ DatasetNLP/           # ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• NLP ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á
‚îú‚îÄ‚îÄ DatasetReasoning/     # ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô Reasoning
‚îú‚îÄ‚îÄ docs/                 # ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö
‚îÇ   ‚îî‚îÄ‚îÄ USAGE.md
‚îú‚îÄ‚îÄ Model/                # ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î/‡∏ù‡∏∂‡∏Å
‚îú‚îÄ‚îÄ Script/               # ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏´‡∏•‡∏±‡∏Å
‚îÇ   ‚îú‚îÄ‚îÄ Dataset/          # ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≤‡∏ò‡∏¥‡∏ï/‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏á‡∏≤‡∏ô
‚îÇ   ‚îú‚îÄ‚îÄ Generate/         # ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
‚îÇ   ‚îú‚îÄ‚îÄ download_model.py
‚îÇ   ‚îî‚îÄ‚îÄ upload_model_to_hf.py
‚îú‚îÄ‚îÄ DataOutput/           # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
‚îú‚îÄ‚îÄ README.md             # ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
‚îú‚îÄ‚îÄ requirements.txt      # (‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á) ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Dependencies
‚îî‚îÄ‚îÄ .env                  # (‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á) ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ Environment Variables
```

## ü§ù ‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏° (Contributing)

‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°! ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ ‡πÇ‡∏õ‡∏£‡∏î‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

1.  Fork ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå
2.  ‡∏™‡∏£‡πâ‡∏≤‡∏á Feature Branch (`git checkout -b feature/AmazingFeature`)
3.  Commit ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (`git commit -m 'Add some AmazingFeature'`)
4.  Push ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Branch (`git push origin feature/AmazingFeature`)
5.  ‡πÄ‡∏õ‡∏¥‡∏î Pull Request

## üìÑ ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï (License)

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï MIT ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå [LICENSE](LICENSE)

---

_‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢: [JonusNattapong/zombitx64]_