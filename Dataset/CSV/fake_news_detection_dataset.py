import csv
import uuid
import os

# ตรวจสอบและสร้างไดเรกทอรี DataOutput หากยังไม่มี
output_dir = 'DataOutput'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# ตัวอย่างข้อมูล Fake News Detection (Text, Label)
# Label: 1 = Fake, 0 = Real
fake_news_data = [
    # Real News Examples
    {"text": "กรมอุตุนิยมวิทยาประกาศเตือนภัยพายุฤดูร้อนในหลายจังหวัดภาคเหนือและภาคอีสาน ช่วงวันที่ 20-22 เมษายนนี้ ขอให้ประชาชนระวังอันตรายจากฝนฟ้าคะนองและลมกระโชกแรง", "label": 0},
    {"text": "ดัชนีตลาดหลักทรัพย์ปิดบวกเล็กน้อย นักลงทุนจับตาการประกาศตัวเลขเงินเฟ้อของสหรัฐฯ ในคืนนี้", "label": 0},
    {"text": "กระทรวงสาธารณสุขยืนยันพบผู้ป่วยโรคฝีดาษวานรรายใหม่ในประเทศ เป็นผู้ที่เดินทางกลับจากต่างประเทศ", "label": 0},
    {"text": "รัฐบาลอนุมัติงบประมาณเพิ่มเติมเพื่อช่วยเหลือเกษตรกรที่ได้รับผลกระทบจากภัยแล้ง", "label": 0},
    {"text": "การแข่งขันฟุตบอลไทยลีกนัดสุดสัปดาห์ที่ผ่านมา ทีมบุรีรัมย์ ยูไนเต็ด เปิดบ้านเอาชนะ เมืองทอง ยูไนเต็ด ไปได้ 2-0", "label": 0},

    # Fake News Examples
    {"text": "ด่วน! พบสารปนเปื้อนร้ายแรงในบะหมี่กึ่งสำเร็จรูปยี่ห้อดัง กินแล้วอาจถึงแก่ชีวิต แชร์ต่อเพื่อเตือนภัย!", "label": 1},
    {"text": "นักวิทยาศาสตร์ค้นพบวิธีชุบชีวิตคนตายได้แล้ว เตรียมเปิดตัวเทคโนโลยีใหม่เร็วๆ นี้!", "label": 1},
    {"text": "ดื่มน้ำมะนาวผสมโซดาทุกวัน ช่วยรักษามะเร็งได้ทุกชนิด ไม่ต้องไปหาหมอ!", "label": 1},
    {"text": "รัฐบาลเตรียมแจกเงินดิจิทัล 1 แสนบาทให้ประชาชนทุกคน แค่กดลิงก์นี้เพื่อลงทะเบียนรับสิทธิ์!", "label": 1},
    {"text": "ภาพถ่ายล่าสุด! พบมนุษย์ต่างดาวเดินปะปนกับผู้คนในกรุงเทพฯ ยืนยันเรื่องจริง 100%", "label": 1},
    {"text": "เตือนภัย! ห้ามรับโทรศัพท์จากเบอร์ที่ไม่รู้จักเด็ดขาด อาจถูกดูดเงินหมดบัญชีทันที!", "label": 1},
    {"text": "องค์การ NASA ยืนยัน อุกกาบาตขนาดใหญ่กำลังจะพุ่งชนโลกในอีก 7 วัน!", "label": 1},
    {"text": "สูตรลับ! กินกระเทียมสดวันละ 10 กลีบ ช่วยลดน้ำหนักได้ 5 กิโลใน 1 สัปดาห์!", "label": 1},
    {"text": "ด่วนที่สุด! ธนาคารแห่งประเทศไทยประกาศยกเลิกใช้ธนบัตรใบละ 1000 บาทรุ่นเก่าทั้งหมด!", "label": 1},
    {"text": "ค้นพบสมุนไพรวิเศษ รักษาโรคเบาหวานให้หายขาดได้ภายใน 1 เดือน!", "label": 1},
    # เพิ่มเติมตัวอย่างตามต้องการ
]

# สร้างรายการข้อมูลพร้อม ID
rows = []
for item in fake_news_data:
    rows.append([str(uuid.uuid4()), item["text"], item["label"]])

# บันทึกเป็นไฟล์ CSV ในโฟลเดอร์ DataOutput
output_file = os.path.join(output_dir, 'thai_dataset_fake_news_detection.csv')
with open(output_file, 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['id', 'text', 'label'])
    writer.writerows(rows)

print(f"Created {output_file}")
